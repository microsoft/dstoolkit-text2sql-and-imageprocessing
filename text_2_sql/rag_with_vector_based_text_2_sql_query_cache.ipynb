{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text2SQL with Semantic Kernel & Azure OpenAI\n",
        "\n",
        "This notebook demonstrates how the SQL plugin can be integrated with Semantic Kernel and Azure OpenAI to answer questions from the database based on the schemas provided. \n",
        "\n",
        "A multi-shot approach is used for SQL generation for more reliable results and reduced token usage. More details can be found in the README.md."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1718623217703
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import yaml\n",
        "import dotenv\n",
        "import json\n",
        "from semantic_kernel.connectors.ai.open_ai import (\n",
        "    AzureChatCompletion,\n",
        ")\n",
        "from semantic_kernel.contents.chat_history import ChatHistory\n",
        "from semantic_kernel.kernel import Kernel\n",
        "from plugins.vector_based_sql_plugin.vector_based_sql_plugin import VectorBasedSQLPlugin\n",
        "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
        "from semantic_kernel.prompt_template.prompt_template_config import PromptTemplateConfig\n",
        "from IPython.display import display, Markdown\n",
        "from ai_search import run_ai_search_query, add_entry_to_index\n",
        "import time\n",
        "logging.basicConfig(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kernel Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "dotenv.load_dotenv()\n",
        "kernel = Kernel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up GPT connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1718623218006
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "service_id = \"chat\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1718623218267
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "chat_service = AzureChatCompletion(\n",
        "    service_id=service_id,\n",
        "    deployment_name=os.environ[\"OpenAI__CompletionDeployment\"],\n",
        "    endpoint=os.environ[\"OpenAI__Endpoint\"],\n",
        "    api_key=os.environ[\"OpenAI__ApiKey\"],\n",
        ")\n",
        "kernel.add_service(chat_service)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1718623218614
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KernelPlugin(name='SQL', description=None, functions={'GetEntitySchema': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='GetEntitySchema', plugin_name='SQL', description='Gets the schema of a view or table in the SQL Database by selecting the most relevant entity based on the search term. Several entities may be returned.', parameters=[KernelParameterMetadata(name='text', description='The text to run a semantic search against. Relevant entities will be returned.', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string', 'description': 'The text to run a semantic search against. Relevant entities will be returned.'}, function_schema_include=True)], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, function_schema_include=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x7f602d980e00>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x7f602d850320>, method=<bound method VectorBasedSQLPlugin.get_entity_schemas of <plugins.vector_based_sql_plugin.vector_based_sql_plugin.VectorBasedSQLPlugin object at 0x7f6002e7be60>>, stream_method=None), 'RunSQLQuery': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='RunSQLQuery', plugin_name='SQL', description='Runs an SQL query against the SQL Database to extract information.', parameters=[KernelParameterMetadata(name='sql_query', description='The SQL query to run against the DB', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string', 'description': 'The SQL query to run against the DB'}, function_schema_include=True)], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, function_schema_include=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x7f602d980e00>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x7f602d850320>, method=<bound method VectorBasedSQLPlugin.run_sql_query of <plugins.vector_based_sql_plugin.vector_based_sql_plugin.VectorBasedSQLPlugin object at 0x7f6002e7be60>>, stream_method=None)})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Register the SQL Plugin with the Database name to use.\n",
        "sql_plugin = VectorBasedSQLPlugin(database=os.environ[\"Text2Sql__DatabaseName\"])\n",
        "kernel.add_plugin(sql_plugin, \"SQL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Prompt Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load prompt and execution settings from the file\n",
        "with open(\"./vector_based_prompt.yaml\", \"r\") as file:\n",
        "    data = yaml.safe_load(file.read())\n",
        "    prompt_template_config = PromptTemplateConfig(**data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_function = kernel.add_function(\n",
        "    prompt_template_config=prompt_template_config,\n",
        "    plugin_name=\"ChatBot\",\n",
        "    function_name=\"Chat\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ChatBot setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = ChatHistory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def ask_question(question: str, chat_history: ChatHistory) -> str:\n",
        "    \"\"\"Asks a question to the chatbot and returns the answer.\n",
        "    \n",
        "    Args:\n",
        "        question (str): The question to ask the chatbot.\n",
        "        chat_history (ChatHistory): The chat history object.\n",
        "        \n",
        "    Returns:\n",
        "        str: The answer from the chatbot.\n",
        "    \"\"\"\n",
        "\n",
        "    start_time = time.time()\n",
        "    cached_schemas = await run_ai_search_query(\n",
        "        question,\n",
        "        [\"QuestionEmbedding\", \"QueryEmbedding\"],\n",
        "        [\"Question\", \"Query\", \"Schemas\"],\n",
        "        os.environ[\"AIService__AzureSearchOptions__Text2SqlQueryCache__Index\"],\n",
        "        os.environ[\"AIService__AzureSearchOptions__Text2SqlQueryCache__SemanticConfig\"],\n",
        "    )\n",
        "\n",
        "    # Create important information prompt that contains the SQL database information.\n",
        "    engine_specific_rules = \"Use TOP X to limit the number of rows returned instead of LIMIT X. NEVER USE LIMIT X as it produces a syntax error.\"\n",
        "    important_information_prompt = f\"\"\"\n",
        "    [SQL DATABASE INFORMATION]\n",
        "    {sql_plugin.system_prompt(engine_specific_rules=engine_specific_rules, query_cache=cached_schemas)}\n",
        "    [END SQL DATABASE INFORMATION]\n",
        "    \"\"\"\n",
        "\n",
        "    arguments = KernelArguments()\n",
        "    arguments[\"chat_history\"] = chat_history\n",
        "    arguments[\"important_information\"] = important_information_prompt\n",
        "    arguments[\"user_input\"] = question\n",
        "\n",
        "    logging.info(\"Question: %s\", question)\n",
        "\n",
        "    answer = await kernel.invoke(\n",
        "        function_name=\"Chat\",\n",
        "        plugin_name=\"ChatBot\",\n",
        "        arguments=arguments,\n",
        "        chat_history=chat_history,\n",
        "    )\n",
        "\n",
        "    logging.info(\"Answer: %s\", answer)\n",
        "\n",
        "    end_time = time.time()\n",
        "    logging.info(\"Time taken: %s\", end_time - start_time)\n",
        "\n",
        "    # Log the question and answer to the chat history.\n",
        "    chat_history.add_user_message(question)\n",
        "    chat_history.add_message({\"role\": \"assistant\", \"message\": answer})\n",
        "\n",
        "    json_answer = json.loads(str(answer))\n",
        "\n",
        "    display(Markdown(json_answer[\"answer\"]))\n",
        "\n",
        "    queries = [source[\"reference\"] for source in json_answer[\"sources\"]]\n",
        "\n",
        "    for query in queries:\n",
        "        entry = {\"Question\": question, \"Query\": query, \"Schemas\": json_answer[\"schemas\"]}\n",
        "        await add_entry_to_index(\n",
        "            entry,\n",
        "            json_answer[\"schemas\"],\n",
        "            os.environ[\"AIService__AzureSearchOptions__Text2SqlQueryCache__Index\"],\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Question: What are the different product categories we have?\n",
            "INFO:semantic_kernel.functions.kernel_function:Function ChatBot-Chat invoking.\n",
            "INFO:semantic_kernel.contents.chat_history:Could not parse prompt <message role=\"system\">\n",
            "As a senior analyst, your primary responsibility is to provide precise and thorough answers to the user's queries. Utilize all the provided functions to craft your responses. You must deliver detailed and accurate final answers with clear explanations and actionable insights.\n",
            "\n",
            "Always use the provided functions to obtain key information in order to answer the question.\n",
            "If you are asked to use always use a function, you must use that function to compliment the answer.\n",
            "Always use multiple functions to formulate the answer.\n",
            "Always execute multiple functions in parallel to compliment the results.\n",
            "\n",
            "The response to the user must meet the requirements in RESPONSE OUTPUT REQUIREMENTS.\n",
            "IMPORTANT INFORMATION contains useful information that you can use to aid your knowledge.\n",
            "CHAT HISTORY contains the previous question and answer pairs in the conversation in JSON format. Do not use this information to answer the question, but to provide context on what was asked previously.\n",
            "\n",
            "[IMPORTANT INFORMATION]\n",
            "\n",
            "\n",
            "    [SQL DATABASE INFORMATION]\n",
            "    Use the &#x27;GetEntitySchema()&#x27; function to search for the most relevant schemas for the data that you wish to obtain. Use the &#x27;RunSQLQuery()&#x27; function to run the SQL query against the database.\n",
            "\n",
            "        Output corresponding text values in the answer for columns where there is an ID. For example, if the column is &#x27;ProductID&#x27;, output the corresponding &#x27;ProductModel&#x27; in the response. Do not include the ID in the response.\n",
            "        If a user is asking for a comparison, always compare the relevant values in the database.\n",
            "\n",
            "        The target database engine is Microsoft TSQL Server, SQL queries must be able compatible to run on Microsoft TSQL Server. \n",
            "        The following Microsoft TSQL Server Syntax rules must be adhered to.\n",
            "        Use TOP X to limit the number of rows returned instead of LIMIT X. NEVER USE LIMIT X as it produces a syntax error.\n",
            "        Always generate the SQL query based on the GetEntitySchema() function output, do not use the chat history data to generate the SQL query.\n",
            "        Only use the column names obtained from GetEntitySchema() when constructing a SQL query, do not make up column names.\n",
            "        You must only provide SELECT SQL queries.\n",
            "        For a given entity, use the &#x27;SelectFromEntity&#x27; property returned from &#x27;GetEntitySchema()&#x27; function in the SELECT FROM part of the SQL query. If the property is {&#x27;SelectFromEntity&#x27;: &#x27;test_schema.test_table&#x27;}, the select statement will be formulated from &#x27;SELECT &lt;VALUES&gt; FROM test_schema.test_table WHERE &lt;CONDITION&gt;.\n",
            "\n",
            "        If you don&#x27;t know how the value is formatted in a column, run a query against the column to get the unique values that might match your query.\n",
            "        Some columns returned from &#x27;GetEntitySchema()&#x27; may have the properties &#x27;AllowedValues&#x27; or &#x27;SampleValues&#x27;. Use these values to determine the possible values that can be used in the SQL query.\n",
            "\n",
            "        The source title to cite is the &#x27;EntityName&#x27; property. The source reference is the SQL query used. The source chunk is the result of the SQL query used to answer the user query in Markdown table format. e.g. { &#x27;title&#x27;: &quot;vProductAndDescription&quot;, &#x27;chunk&#x27;: &#x27;| ProductID | Name              | ProductModel | Culture | Description                      |\\n|-----------|-------------------|--------------|---------|----------------------------------|\\n| 101       | Mountain Bike     | MT-100       | en      | A durable bike for mountain use. |\\n| 102       | Road Bike         | RB-200       | en      | Lightweight bike for road use.   |\\n| 103       | Hybrid Bike       | HB-300       | fr      | V\u00e9lo hybride pour usage mixte.   |\\n&#x27;, &#x27;reference&#x27;: &#x27;SELECT ProductID, Name, ProductModel, Culture, Description FROM vProductAndDescription WHERE Culture = &quot;en&quot;;&#x27; }\n",
            "    [END SQL DATABASE INFORMATION]\n",
            "    \n",
            "\n",
            "[END IMPORTANT INFORMATION]\n",
            "\n",
            "[RESPONSE OUTPUT REQUIREMENTS]\n",
            "\n",
            "  The answer MUST be returned in JSON format as { \"answer\": \"<GENERATED ANSWER>\", \"sources\": [ {\"title\": <SOURCE 1 TITLE>, \"chunk\": <SOURCE 1 CONTEXT CHUNK>, \"reference\": \"<SOURCE 1 REFERENCE>\"}, {\"title\": <SOURCE 2 TITLE>, \"chunk\": <SOURCE 2 CONTEXT CHUNK>, \"reference\": \"<SOURCE 2 REFERENCE>\"} ] }.\n",
            "\n",
            "  The 'answer' property MUST meet the requirements in the ANSWER PROPERTY REQUIREMENTS.\n",
            "  The 'sources' property MUST meet the requirements in the SOURCES PROPERTY REQUIREMENTS.\n",
            "\n",
            "  Do NOT return anything outside of the provided JSON property. Ensure that this is valid JSON returned.\n",
            "\n",
            "  Never return an empty response or null value. Always answer the question.\n",
            "\n",
            "  [ANSWER PROPERTY REQUIREMENTS]\n",
            "    1. Language and Tone:\n",
            "      Use only British English throughout the response.\n",
            "      Employ a business-friendly language that is professional and easy to understand.\n",
            "\n",
            "    2. Content Restrictions:\n",
            "      Do not use any profanity, offensive language, hate speech, or code in the response.\n",
            "      If you encounter any such content, handle it gracefully by omitting or rephrasing it appropriately.\n",
            "\n",
            "    3. Information Sources:\n",
            "      Use only information from the provided functions and specified important information.\n",
            "      Do not use any external sources or the chat history for constructing the response.\n",
            "      In case of conflicting information, prioritize data from the SQL Database as the primary source of truth.\n",
            "\n",
            "    4. Calculations:\n",
            "      For any required calculations, use only the values provided in the context.\n",
            "      Provide a brief, clear explanation of the calculations beneath the results.\n",
            "\n",
            "    5. Response Structure:\n",
            "      Ensure the response is direct, easy to understand, and well-structured.\n",
            "      Format the response using Markdown for clarity and readability.\n",
            "      Use bold sub-headings for clarity where needed. Only use Markdown headings Level 3 (###) and Level 4 (####).\n",
            "      Use bullet points or numbered lists when appropriate.\n",
            "      Do not vary the font size within the same sentence.\n",
            "\n",
            "    6. Citations:\n",
            "      All factual information used in the answer must be cited with numbered references. For example, [1] should be used to refer to the first source.\n",
            "      Each citation in the answer must correspond to a single entry in the 'sources' object.\n",
            "      The same citation and corresponding context chunk may be used multiple times if needed.\n",
            "      Place the numbered citation at the end of each relevant sentence that uses information from the sources.\n",
            "      Ensure that each source listed in the 'sources' property is cited at least once in the answer.\n",
            "      Do not provide a list of definitions from the business glossary; use such information only to enhance the answer contextually.\n",
            "\n",
            "    7. Citations Format:\n",
            "      Citations should be embedded within the text, not as a separate list at the end of the 'answer' property.\n",
            "  [END ANSWER PROPERTY REQUIREMENTS]\n",
            "\n",
            "  [SOURCES PROPERTY REQUIREMENTS]\n",
            "    1. Reference Inclusion:\n",
            "      Include all corresponding references for all cited content in the 'answer' property.\n",
            "      Place the references in the 'sources' property.\n",
            "\n",
            "    2. Source Format:\n",
            "      Each entry in the 'sources' property must be formatted as: {\"title\": \"<SOURCE TITLE>\", \"chunk\": \"<SOURCE CONTEXT CHUNK>\", \"reference\": \"<SOURCE REFERENCE>\"}\n",
            "      For example, a complete response with two citations would be formatted as: { \"answer\": \"<GENERATED ANSWER>\", \"sources\": [ {\"title\": <SOURCE 1 TITLE>, \"chunk\": <SOURCE 1 CONTEXT CHUNK>, \"reference\": \"<SOURCE 1 REFERENCE>\"}, {\"title\": <SOURCE 2 TITLE>, \"chunk\": <SOURCE 2 CONTEXT CHUNK>, \"reference\": \"<SOURCE 2 REFERENCE>\"} ] }\n",
            "\n",
            "    3. Source Chunk:\n",
            "      The 'chunk' property should contain a concise, unedited snippet of the relevant context that supports the answer.\n",
            "\n",
            "    4. Mandatory References:\n",
            "      Ensure that every citation in the 'answer' has a corresponding entry in the 'sources' property.\n",
            "      Every entry in the 'sources' property must be cited at least once in the answer.\n",
            "  [END SOURCES PROPERTY REQUIREMENTS]\n",
            "\n",
            "[END RESPONSE OUTPUT REQUIREMENTS]\n",
            "</message>\n",
            "<chat_history />\n",
            "<message role=\"user\">What are the different product categories we have?</message> as xml, treating as text, error was: not well-formed (invalid token): line 41, column 78\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=51, prompt_tokens=1815, total_tokens=1866)\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_chat_completion_base:processing 2 tool calls in parallel.\n",
            "INFO:semantic_kernel.kernel:Calling SQL-GetEntitySchema function with args: {\"text\": \"Product Category\"}\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-GetEntitySchema invoking.\n",
            "INFO:semantic_kernel.kernel:Calling SQL-GetEntitySchema function with args: {\"text\": \"Product\"}\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-GetEntitySchema invoking.\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-03-15-preview \"HTTP/1.1 200 OK\"\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://open-ai-vector-db.search.windows.net/indexes('text-2-sql-index')/docs/search.post.search?api-version=REDACTED'\n",
            "Request method: 'POST'\n",
            "Request headers:\n",
            "    'Content-Type': 'application/json'\n",
            "    'Content-Length': '34765'\n",
            "    'api-key': 'REDACTED'\n",
            "    'Accept': 'application/json;odata.metadata=none'\n",
            "    'x-ms-client-request-id': '435b3768-706a-11ef-ae73-0242ac110002'\n",
            "    'User-Agent': 'azsdk-python-search-documents/11.6.0b4 Python/3.12.3 (Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36)'\n",
            "A body is sent with the request\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-03-15-preview \"HTTP/1.1 200 OK\"\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://open-ai-vector-db.search.windows.net/indexes('text-2-sql-index')/docs/search.post.search?api-version=REDACTED'\n",
            "Request method: 'POST'\n",
            "Request headers:\n",
            "    'Content-Type': 'application/json'\n",
            "    'Content-Length': '34721'\n",
            "    'api-key': 'REDACTED'\n",
            "    'Accept': 'application/json;odata.metadata=none'\n",
            "    'x-ms-client-request-id': '4360c9a8-706a-11ef-ae73-0242ac110002'\n",
            "    'User-Agent': 'azsdk-python-search-documents/11.6.0b4 Python/3.12.3 (Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36)'\n",
            "A body is sent with the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 200\n",
            "Response headers:\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
            "    'Content-Encoding': 'REDACTED'\n",
            "    'Vary': 'REDACTED'\n",
            "    'Server': 'Microsoft-IIS/10.0'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Preference-Applied': 'REDACTED'\n",
            "    'OData-Version': 'REDACTED'\n",
            "    'request-id': '435b3768-706a-11ef-ae73-0242ac110002'\n",
            "    'elapsed-time': 'REDACTED'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Date': 'Wed, 11 Sep 2024 18:18:39 GMT'\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-GetEntitySchema succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.590935s\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 200\n",
            "Response headers:\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
            "    'Content-Encoding': 'REDACTED'\n",
            "    'Vary': 'REDACTED'\n",
            "    'Server': 'Microsoft-IIS/10.0'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Preference-Applied': 'REDACTED'\n",
            "    'OData-Version': 'REDACTED'\n",
            "    'request-id': '4360c9a8-706a-11ef-ae73-0242ac110002'\n",
            "    'elapsed-time': 'REDACTED'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Date': 'Wed, 11 Sep 2024 18:18:39 GMT'\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-GetEntitySchema succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.566008s\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client:Retrying request to /chat/completions in 1.000000 seconds\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=34, prompt_tokens=5818, total_tokens=5852)\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_chat_completion_base:processing 1 tool calls in parallel.\n",
            "INFO:semantic_kernel.kernel:Calling SQL-RunSQLQuery function with args: {\"sql_query\":\"SELECT ParentProductCategoryName, ProductCategoryName FROM SalesLT.vGetAllCategories;\"}\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-RunSQLQuery invoking.\n",
            "INFO:root:Executing SQL Query\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-RunSQLQuery succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.369210s\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=636, prompt_tokens=6556, total_tokens=7192)\n",
            "INFO:semantic_kernel.functions.kernel_function:Function ChatBot-Chat succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 9.696862s\n",
            "INFO:root:Answer: {\n",
            "  \"answer\": \"Our product categories are organised into several parent categories, each containing multiple subcategories. Here is a detailed list of the different product categories we have:\\n\\n### Accessories\\n- Bike Racks\\n- Bike Stands\\n- Bottles and Cages\\n- Cleaners\\n- Fenders\\n- Helmets\\n- Hydration Packs\\n- Lights\\n- Locks\\n- Panniers\\n- Pumps\\n- Tires and Tubes\\n\\n### Clothing\\n- Bib-Shorts\\n- Caps\\n- Gloves\\n- Jerseys\\n- Shorts\\n- Socks\\n- Tights\\n- Vests\\n\\n### Components\\n- Handlebars\\n- Bottom Brackets\\n- Brakes\\n- Chains\\n- Cranksets\\n- Derailleurs\\n- Forks\\n- Headsets\\n- Mountain Frames\\n- Pedals\\n- Road Frames\\n- Saddles\\n- Touring Frames\\n- Wheels\\n\\n### Bikes\\n- Mountain Bikes\\n- Road Bikes\\n- Touring Bikes\\n\\nThese categories help in better organising and managing our product inventory, making it easier for customers to find what they need [1].\",\n",
            "  \"sources\": [\n",
            "    {\n",
            "      \"title\": \"Get All Categories\",\n",
            "      \"chunk\": \"| ParentProductCategoryName | ProductCategoryName |\\n|---------------------------|---------------------|\\n| Accessories               | Bike Racks          |\\n| Accessories               | Bike Stands         |\\n| Accessories               | Bottles and Cages   |\\n| Accessories               | Cleaners            |\\n| Accessories               | Fenders             |\\n| Accessories               | Helmets             |\\n| Accessories               | Hydration Packs     |\\n| Accessories               | Lights              |\\n| Accessories               | Locks               |\\n| Accessories               | Panniers            |\\n| Accessories               | Pumps               |\\n| Accessories               | Tires and Tubes     |\\n| Clothing                  | Bib-Shorts          |\\n| Clothing                  | Caps                |\\n| Clothing                  | Gloves              |\\n| Clothing                  | Jerseys             |\\n| Clothing                  | Shorts              |\\n| Clothing                  | Socks               |\\n| Clothing                  | Tights              |\\n| Clothing                  | Vests               |\\n| Components                | Handlebars          |\\n| Components                | Bottom Brackets     |\\n| Components                | Brakes              |\\n| Components                | Chains              |\\n| Components                | Cranksets           |\\n| Components                | Derailleurs         |\\n| Components                | Forks               |\\n| Components                | Headsets            |\\n| Components                | Mountain Frames     |\\n| Components                | Pedals              |\\n| Components                | Road Frames         |\\n| Components                | Saddles             |\\n| Components                | Touring Frames      |\\n| Components                | Wheels              |\\n| Bikes                     | Mountain Bikes      |\\n| Bikes                     | Road Bikes          |\\n| Bikes                     | Touring Bikes       |\\n\",\n",
            "      \"reference\": \"SELECT ParentProductCategoryName, ProductCategoryName FROM SalesLT.vGetAllCategories;\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Our product categories are organised into several parent categories, each containing multiple subcategories. Here is a detailed list of the different product categories we have:\n",
              "\n",
              "### Accessories\n",
              "- Bike Racks\n",
              "- Bike Stands\n",
              "- Bottles and Cages\n",
              "- Cleaners\n",
              "- Fenders\n",
              "- Helmets\n",
              "- Hydration Packs\n",
              "- Lights\n",
              "- Locks\n",
              "- Panniers\n",
              "- Pumps\n",
              "- Tires and Tubes\n",
              "\n",
              "### Clothing\n",
              "- Bib-Shorts\n",
              "- Caps\n",
              "- Gloves\n",
              "- Jerseys\n",
              "- Shorts\n",
              "- Socks\n",
              "- Tights\n",
              "- Vests\n",
              "\n",
              "### Components\n",
              "- Handlebars\n",
              "- Bottom Brackets\n",
              "- Brakes\n",
              "- Chains\n",
              "- Cranksets\n",
              "- Derailleurs\n",
              "- Forks\n",
              "- Headsets\n",
              "- Mountain Frames\n",
              "- Pedals\n",
              "- Road Frames\n",
              "- Saddles\n",
              "- Touring Frames\n",
              "- Wheels\n",
              "\n",
              "### Bikes\n",
              "- Mountain Bikes\n",
              "- Road Bikes\n",
              "- Touring Bikes\n",
              "\n",
              "These categories help in better organising and managing our product inventory, making it easier for customers to find what they need [1]."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "await ask_question(\"What are the different product categories we have?\", history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Question: What is the top performing product by quantity of units sold?\n",
            "INFO:semantic_kernel.functions.kernel_function:Function ChatBot-Chat invoking.\n",
            "INFO:semantic_kernel.contents.chat_history:Could not parse prompt <message role=\"system\">\n",
            "As a senior analyst, your primary responsibility is to provide precise and thorough answers to the user's queries. Utilize all the provided functions to craft your responses. You must deliver detailed and accurate final answers with clear explanations and actionable insights.\n",
            "\n",
            "Always use the provided functions to obtain key information in order to answer the question.\n",
            "If you are asked to use always use a function, you must use that function to compliment the answer.\n",
            "Always use multiple functions to formulate the answer.\n",
            "Always execute multiple functions in parallel to compliment the results.\n",
            "\n",
            "The response to the user must meet the requirements in RESPONSE OUTPUT REQUIREMENTS.\n",
            "IMPORTANT INFORMATION contains useful information that you can use to aid your knowledge.\n",
            "CHAT HISTORY contains the previous question and answer pairs in the conversation in JSON format. Do not use this information to answer the question, but to provide context on what was asked previously.\n",
            "\n",
            "[IMPORTANT INFORMATION]\n",
            "\n",
            "\n",
            "    [SQL DATABASE INFORMATION]\n",
            "    Use the &#x27;GetEntitySchema()&#x27; function to search for the most relevant schemas for the data that you wish to obtain. Use the &#x27;RunSQLQuery()&#x27; function to run the SQL query against the database.\n",
            "\n",
            "        Output corresponding text values in the answer for columns where there is an ID. For example, if the column is &#x27;ProductID&#x27;, output the corresponding &#x27;ProductModel&#x27; in the response. Do not include the ID in the response.\n",
            "        If a user is asking for a comparison, always compare the relevant values in the database.\n",
            "\n",
            "        The target database engine is Microsoft TSQL Server, SQL queries must be able compatible to run on Microsoft TSQL Server. \n",
            "        The following Microsoft TSQL Server Syntax rules must be adhered to.\n",
            "        Use TOP X to limit the number of rows returned instead of LIMIT X. NEVER USE LIMIT X as it produces a syntax error.\n",
            "        Always generate the SQL query based on the GetEntitySchema() function output, do not use the chat history data to generate the SQL query.\n",
            "        Only use the column names obtained from GetEntitySchema() when constructing a SQL query, do not make up column names.\n",
            "        You must only provide SELECT SQL queries.\n",
            "        For a given entity, use the &#x27;SelectFromEntity&#x27; property returned from &#x27;GetEntitySchema()&#x27; function in the SELECT FROM part of the SQL query. If the property is {&#x27;SelectFromEntity&#x27;: &#x27;test_schema.test_table&#x27;}, the select statement will be formulated from &#x27;SELECT &lt;VALUES&gt; FROM test_schema.test_table WHERE &lt;CONDITION&gt;.\n",
            "\n",
            "        If you don&#x27;t know how the value is formatted in a column, run a query against the column to get the unique values that might match your query.\n",
            "        Some columns returned from &#x27;GetEntitySchema()&#x27; may have the properties &#x27;AllowedValues&#x27; or &#x27;SampleValues&#x27;. Use these values to determine the possible values that can be used in the SQL query.\n",
            "\n",
            "        The source title to cite is the &#x27;EntityName&#x27; property. The source reference is the SQL query used. The source chunk is the result of the SQL query used to answer the user query in Markdown table format. e.g. { &#x27;title&#x27;: &quot;vProductAndDescription&quot;, &#x27;chunk&#x27;: &#x27;| ProductID | Name              | ProductModel | Culture | Description                      |\\n|-----------|-------------------|--------------|---------|----------------------------------|\\n| 101       | Mountain Bike     | MT-100       | en      | A durable bike for mountain use. |\\n| 102       | Road Bike         | RB-200       | en      | Lightweight bike for road use.   |\\n| 103       | Hybrid Bike       | HB-300       | fr      | V\u00e9lo hybride pour usage mixte.   |\\n&#x27;, &#x27;reference&#x27;: &#x27;SELECT ProductID, Name, ProductModel, Culture, Description FROM vProductAndDescription WHERE Culture = &quot;en&quot;;&#x27; }\n",
            "    [END SQL DATABASE INFORMATION]\n",
            "    \n",
            "\n",
            "[END IMPORTANT INFORMATION]\n",
            "\n",
            "[RESPONSE OUTPUT REQUIREMENTS]\n",
            "\n",
            "  The answer MUST be returned in JSON format as { \"answer\": \"<GENERATED ANSWER>\", \"sources\": [ {\"title\": <SOURCE 1 TITLE>, \"chunk\": <SOURCE 1 CONTEXT CHUNK>, \"reference\": \"<SOURCE 1 REFERENCE>\"}, {\"title\": <SOURCE 2 TITLE>, \"chunk\": <SOURCE 2 CONTEXT CHUNK>, \"reference\": \"<SOURCE 2 REFERENCE>\"} ] }.\n",
            "\n",
            "  The 'answer' property MUST meet the requirements in the ANSWER PROPERTY REQUIREMENTS.\n",
            "  The 'sources' property MUST meet the requirements in the SOURCES PROPERTY REQUIREMENTS.\n",
            "\n",
            "  Do NOT return anything outside of the provided JSON property. Ensure that this is valid JSON returned.\n",
            "\n",
            "  Never return an empty response or null value. Always answer the question.\n",
            "\n",
            "  [ANSWER PROPERTY REQUIREMENTS]\n",
            "    1. Language and Tone:\n",
            "      Use only British English throughout the response.\n",
            "      Employ a business-friendly language that is professional and easy to understand.\n",
            "\n",
            "    2. Content Restrictions:\n",
            "      Do not use any profanity, offensive language, hate speech, or code in the response.\n",
            "      If you encounter any such content, handle it gracefully by omitting or rephrasing it appropriately.\n",
            "\n",
            "    3. Information Sources:\n",
            "      Use only information from the provided functions and specified important information.\n",
            "      Do not use any external sources or the chat history for constructing the response.\n",
            "      In case of conflicting information, prioritize data from the SQL Database as the primary source of truth.\n",
            "\n",
            "    4. Calculations:\n",
            "      For any required calculations, use only the values provided in the context.\n",
            "      Provide a brief, clear explanation of the calculations beneath the results.\n",
            "\n",
            "    5. Response Structure:\n",
            "      Ensure the response is direct, easy to understand, and well-structured.\n",
            "      Format the response using Markdown for clarity and readability.\n",
            "      Use bold sub-headings for clarity where needed. Only use Markdown headings Level 3 (###) and Level 4 (####).\n",
            "      Use bullet points or numbered lists when appropriate.\n",
            "      Do not vary the font size within the same sentence.\n",
            "\n",
            "    6. Citations:\n",
            "      All factual information used in the answer must be cited with numbered references. For example, [1] should be used to refer to the first source.\n",
            "      Each citation in the answer must correspond to a single entry in the 'sources' object.\n",
            "      The same citation and corresponding context chunk may be used multiple times if needed.\n",
            "      Place the numbered citation at the end of each relevant sentence that uses information from the sources.\n",
            "      Ensure that each source listed in the 'sources' property is cited at least once in the answer.\n",
            "      Do not provide a list of definitions from the business glossary; use such information only to enhance the answer contextually.\n",
            "\n",
            "    7. Citations Format:\n",
            "      Citations should be embedded within the text, not as a separate list at the end of the 'answer' property.\n",
            "  [END ANSWER PROPERTY REQUIREMENTS]\n",
            "\n",
            "  [SOURCES PROPERTY REQUIREMENTS]\n",
            "    1. Reference Inclusion:\n",
            "      Include all corresponding references for all cited content in the 'answer' property.\n",
            "      Place the references in the 'sources' property.\n",
            "\n",
            "    2. Source Format:\n",
            "      Each entry in the 'sources' property must be formatted as: {\"title\": \"<SOURCE TITLE>\", \"chunk\": \"<SOURCE CONTEXT CHUNK>\", \"reference\": \"<SOURCE REFERENCE>\"}\n",
            "      For example, a complete response with two citations would be formatted as: { \"answer\": \"<GENERATED ANSWER>\", \"sources\": [ {\"title\": <SOURCE 1 TITLE>, \"chunk\": <SOURCE 1 CONTEXT CHUNK>, \"reference\": \"<SOURCE 1 REFERENCE>\"}, {\"title\": <SOURCE 2 TITLE>, \"chunk\": <SOURCE 2 CONTEXT CHUNK>, \"reference\": \"<SOURCE 2 REFERENCE>\"} ] }\n",
            "\n",
            "    3. Source Chunk:\n",
            "      The 'chunk' property should contain a concise, unedited snippet of the relevant context that supports the answer.\n",
            "\n",
            "    4. Mandatory References:\n",
            "      Ensure that every citation in the 'answer' has a corresponding entry in the 'sources' property.\n",
            "      Every entry in the 'sources' property must be cited at least once in the answer.\n",
            "  [END SOURCES PROPERTY REQUIREMENTS]\n",
            "\n",
            "[END RESPONSE OUTPUT REQUIREMENTS]\n",
            "</message>\n",
            "<chat_history><message role=\"user\"><text>What are the different product categories we have?</text></message><message role=\"assistant\" /></chat_history>\n",
            "<message role=\"user\">What is the top performing product by quantity of units sold?</message> as xml, treating as text, error was: not well-formed (invalid token): line 41, column 78\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=51, prompt_tokens=1847, total_tokens=1898)\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_chat_completion_base:processing 2 tool calls in parallel.\n",
            "INFO:semantic_kernel.kernel:Calling SQL-GetEntitySchema function with args: {\"text\": \"product sales\"}\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-GetEntitySchema invoking.\n",
            "INFO:semantic_kernel.kernel:Calling SQL-GetEntitySchema function with args: {\"text\": \"products\"}\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-GetEntitySchema invoking.\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-03-15-preview \"HTTP/1.1 200 OK\"\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://open-ai-vector-db.search.windows.net/indexes('text-2-sql-index')/docs/search.post.search?api-version=REDACTED'\n",
            "Request method: 'POST'\n",
            "Request headers:\n",
            "    'Content-Type': 'application/json'\n",
            "    'Content-Length': '34711'\n",
            "    'api-key': 'REDACTED'\n",
            "    'Accept': 'application/json;odata.metadata=none'\n",
            "    'x-ms-client-request-id': '48f29234-706a-11ef-ae73-0242ac110002'\n",
            "    'User-Agent': 'azsdk-python-search-documents/11.6.0b4 Python/3.12.3 (Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36)'\n",
            "A body is sent with the request\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-03-15-preview \"HTTP/1.1 200 OK\"\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://open-ai-vector-db.search.windows.net/indexes('text-2-sql-index')/docs/search.post.search?api-version=REDACTED'\n",
            "Request method: 'POST'\n",
            "Request headers:\n",
            "    'Content-Type': 'application/json'\n",
            "    'Content-Length': '34720'\n",
            "    'api-key': 'REDACTED'\n",
            "    'Accept': 'application/json;odata.metadata=none'\n",
            "    'x-ms-client-request-id': '48f7c98e-706a-11ef-ae73-0242ac110002'\n",
            "    'User-Agent': 'azsdk-python-search-documents/11.6.0b4 Python/3.12.3 (Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36)'\n",
            "A body is sent with the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 200\n",
            "Response headers:\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
            "    'Content-Encoding': 'REDACTED'\n",
            "    'Vary': 'REDACTED'\n",
            "    'Server': 'Microsoft-IIS/10.0'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Preference-Applied': 'REDACTED'\n",
            "    'OData-Version': 'REDACTED'\n",
            "    'request-id': '48f29234-706a-11ef-ae73-0242ac110002'\n",
            "    'elapsed-time': 'REDACTED'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Date': 'Wed, 11 Sep 2024 18:18:48 GMT'\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-GetEntitySchema succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.482475s\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 200\n",
            "Response headers:\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
            "    'Content-Encoding': 'REDACTED'\n",
            "    'Vary': 'REDACTED'\n",
            "    'Server': 'Microsoft-IIS/10.0'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Preference-Applied': 'REDACTED'\n",
            "    'OData-Version': 'REDACTED'\n",
            "    'request-id': '48f7c98e-706a-11ef-ae73-0242ac110002'\n",
            "    'elapsed-time': 'REDACTED'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Date': 'Wed, 11 Sep 2024 18:18:48 GMT'\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-GetEntitySchema succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.533455s\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=65, prompt_tokens=5827, total_tokens=5892)\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_chat_completion_base:processing 1 tool calls in parallel.\n",
            "INFO:semantic_kernel.kernel:Calling SQL-RunSQLQuery function with args: {\"sql_query\":\"SELECT TOP 1 p.Name, SUM(d.OrderQty) AS TotalUnitsSold FROM SalesLT.SalesOrderDetail d JOIN SalesLT.Product p ON d.ProductID = p.ProductID GROUP BY p.Name ORDER BY TotalUnitsSold DESC;\"}\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-RunSQLQuery invoking.\n",
            "INFO:root:Executing SQL Query\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-RunSQLQuery succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.301421s\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=142, prompt_tokens=5921, total_tokens=6063)\n",
            "INFO:semantic_kernel.functions.kernel_function:Function ChatBot-Chat succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 3.936345s\n",
            "INFO:root:Answer: { \n",
            "  \"answer\": \"The top performing product by quantity of units sold is the 'Classic Vest, S' with a total of 87 units sold [1].\",\n",
            "  \"sources\": [\n",
            "    {\n",
            "      \"title\": \"Sales Order Detail\",\n",
            "      \"chunk\": \"| Name          | TotalUnitsSold |\\n|---------------|----------------|\\n| Classic Vest, S | 87             |\\n\",\n",
            "      \"reference\": \"SELECT TOP 1 p.Name, SUM(d.OrderQty) AS TotalUnitsSold FROM SalesLT.SalesOrderDetail d JOIN SalesLT.Product p ON d.ProductID = p.ProductID GROUP BY p.Name ORDER BY TotalUnitsSold DESC;\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The top performing product by quantity of units sold is the 'Classic Vest, S' with a total of 87 units sold [1]."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "await ask_question(\"What is the top performing product by quantity of units sold?\", history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Question: Which country did we sell the most to in June 2008?\n",
            "INFO:semantic_kernel.functions.kernel_function:Function ChatBot-Chat invoking.\n",
            "INFO:semantic_kernel.contents.chat_history:Could not parse prompt <message role=\"system\">\n",
            "As a senior analyst, your primary responsibility is to provide precise and thorough answers to the user's queries. Utilize all the provided functions to craft your responses. You must deliver detailed and accurate final answers with clear explanations and actionable insights.\n",
            "\n",
            "Always use the provided functions to obtain key information in order to answer the question.\n",
            "If you are asked to use always use a function, you must use that function to compliment the answer.\n",
            "Always use multiple functions to formulate the answer.\n",
            "Always execute multiple functions in parallel to compliment the results.\n",
            "\n",
            "The response to the user must meet the requirements in RESPONSE OUTPUT REQUIREMENTS.\n",
            "IMPORTANT INFORMATION contains useful information that you can use to aid your knowledge.\n",
            "CHAT HISTORY contains the previous question and answer pairs in the conversation in JSON format. Do not use this information to answer the question, but to provide context on what was asked previously.\n",
            "\n",
            "[IMPORTANT INFORMATION]\n",
            "\n",
            "\n",
            "    [SQL DATABASE INFORMATION]\n",
            "    Use the &#x27;GetEntitySchema()&#x27; function to search for the most relevant schemas for the data that you wish to obtain. Use the &#x27;RunSQLQuery()&#x27; function to run the SQL query against the database.\n",
            "\n",
            "        Output corresponding text values in the answer for columns where there is an ID. For example, if the column is &#x27;ProductID&#x27;, output the corresponding &#x27;ProductModel&#x27; in the response. Do not include the ID in the response.\n",
            "        If a user is asking for a comparison, always compare the relevant values in the database.\n",
            "\n",
            "        The target database engine is Microsoft TSQL Server, SQL queries must be able compatible to run on Microsoft TSQL Server. \n",
            "        The following Microsoft TSQL Server Syntax rules must be adhered to.\n",
            "        Use TOP X to limit the number of rows returned instead of LIMIT X. NEVER USE LIMIT X as it produces a syntax error.\n",
            "        Always generate the SQL query based on the GetEntitySchema() function output, do not use the chat history data to generate the SQL query.\n",
            "        Only use the column names obtained from GetEntitySchema() when constructing a SQL query, do not make up column names.\n",
            "        You must only provide SELECT SQL queries.\n",
            "        For a given entity, use the &#x27;SelectFromEntity&#x27; property returned from &#x27;GetEntitySchema()&#x27; function in the SELECT FROM part of the SQL query. If the property is {&#x27;SelectFromEntity&#x27;: &#x27;test_schema.test_table&#x27;}, the select statement will be formulated from &#x27;SELECT &lt;VALUES&gt; FROM test_schema.test_table WHERE &lt;CONDITION&gt;.\n",
            "\n",
            "        If you don&#x27;t know how the value is formatted in a column, run a query against the column to get the unique values that might match your query.\n",
            "        Some columns returned from &#x27;GetEntitySchema()&#x27; may have the properties &#x27;AllowedValues&#x27; or &#x27;SampleValues&#x27;. Use these values to determine the possible values that can be used in the SQL query.\n",
            "\n",
            "        The source title to cite is the &#x27;EntityName&#x27; property. The source reference is the SQL query used. The source chunk is the result of the SQL query used to answer the user query in Markdown table format. e.g. { &#x27;title&#x27;: &quot;vProductAndDescription&quot;, &#x27;chunk&#x27;: &#x27;| ProductID | Name              | ProductModel | Culture | Description                      |\\n|-----------|-------------------|--------------|---------|----------------------------------|\\n| 101       | Mountain Bike     | MT-100       | en      | A durable bike for mountain use. |\\n| 102       | Road Bike         | RB-200       | en      | Lightweight bike for road use.   |\\n| 103       | Hybrid Bike       | HB-300       | fr      | V\u00e9lo hybride pour usage mixte.   |\\n&#x27;, &#x27;reference&#x27;: &#x27;SELECT ProductID, Name, ProductModel, Culture, Description FROM vProductAndDescription WHERE Culture = &quot;en&quot;;&#x27; }\n",
            "    [END SQL DATABASE INFORMATION]\n",
            "    \n",
            "\n",
            "[END IMPORTANT INFORMATION]\n",
            "\n",
            "[RESPONSE OUTPUT REQUIREMENTS]\n",
            "\n",
            "  The answer MUST be returned in JSON format as { \"answer\": \"<GENERATED ANSWER>\", \"sources\": [ {\"title\": <SOURCE 1 TITLE>, \"chunk\": <SOURCE 1 CONTEXT CHUNK>, \"reference\": \"<SOURCE 1 REFERENCE>\"}, {\"title\": <SOURCE 2 TITLE>, \"chunk\": <SOURCE 2 CONTEXT CHUNK>, \"reference\": \"<SOURCE 2 REFERENCE>\"} ] }.\n",
            "\n",
            "  The 'answer' property MUST meet the requirements in the ANSWER PROPERTY REQUIREMENTS.\n",
            "  The 'sources' property MUST meet the requirements in the SOURCES PROPERTY REQUIREMENTS.\n",
            "\n",
            "  Do NOT return anything outside of the provided JSON property. Ensure that this is valid JSON returned.\n",
            "\n",
            "  Never return an empty response or null value. Always answer the question.\n",
            "\n",
            "  [ANSWER PROPERTY REQUIREMENTS]\n",
            "    1. Language and Tone:\n",
            "      Use only British English throughout the response.\n",
            "      Employ a business-friendly language that is professional and easy to understand.\n",
            "\n",
            "    2. Content Restrictions:\n",
            "      Do not use any profanity, offensive language, hate speech, or code in the response.\n",
            "      If you encounter any such content, handle it gracefully by omitting or rephrasing it appropriately.\n",
            "\n",
            "    3. Information Sources:\n",
            "      Use only information from the provided functions and specified important information.\n",
            "      Do not use any external sources or the chat history for constructing the response.\n",
            "      In case of conflicting information, prioritize data from the SQL Database as the primary source of truth.\n",
            "\n",
            "    4. Calculations:\n",
            "      For any required calculations, use only the values provided in the context.\n",
            "      Provide a brief, clear explanation of the calculations beneath the results.\n",
            "\n",
            "    5. Response Structure:\n",
            "      Ensure the response is direct, easy to understand, and well-structured.\n",
            "      Format the response using Markdown for clarity and readability.\n",
            "      Use bold sub-headings for clarity where needed. Only use Markdown headings Level 3 (###) and Level 4 (####).\n",
            "      Use bullet points or numbered lists when appropriate.\n",
            "      Do not vary the font size within the same sentence.\n",
            "\n",
            "    6. Citations:\n",
            "      All factual information used in the answer must be cited with numbered references. For example, [1] should be used to refer to the first source.\n",
            "      Each citation in the answer must correspond to a single entry in the 'sources' object.\n",
            "      The same citation and corresponding context chunk may be used multiple times if needed.\n",
            "      Place the numbered citation at the end of each relevant sentence that uses information from the sources.\n",
            "      Ensure that each source listed in the 'sources' property is cited at least once in the answer.\n",
            "      Do not provide a list of definitions from the business glossary; use such information only to enhance the answer contextually.\n",
            "\n",
            "    7. Citations Format:\n",
            "      Citations should be embedded within the text, not as a separate list at the end of the 'answer' property.\n",
            "  [END ANSWER PROPERTY REQUIREMENTS]\n",
            "\n",
            "  [SOURCES PROPERTY REQUIREMENTS]\n",
            "    1. Reference Inclusion:\n",
            "      Include all corresponding references for all cited content in the 'answer' property.\n",
            "      Place the references in the 'sources' property.\n",
            "\n",
            "    2. Source Format:\n",
            "      Each entry in the 'sources' property must be formatted as: {\"title\": \"<SOURCE TITLE>\", \"chunk\": \"<SOURCE CONTEXT CHUNK>\", \"reference\": \"<SOURCE REFERENCE>\"}\n",
            "      For example, a complete response with two citations would be formatted as: { \"answer\": \"<GENERATED ANSWER>\", \"sources\": [ {\"title\": <SOURCE 1 TITLE>, \"chunk\": <SOURCE 1 CONTEXT CHUNK>, \"reference\": \"<SOURCE 1 REFERENCE>\"}, {\"title\": <SOURCE 2 TITLE>, \"chunk\": <SOURCE 2 CONTEXT CHUNK>, \"reference\": \"<SOURCE 2 REFERENCE>\"} ] }\n",
            "\n",
            "    3. Source Chunk:\n",
            "      The 'chunk' property should contain a concise, unedited snippet of the relevant context that supports the answer.\n",
            "\n",
            "    4. Mandatory References:\n",
            "      Ensure that every citation in the 'answer' has a corresponding entry in the 'sources' property.\n",
            "      Every entry in the 'sources' property must be cited at least once in the answer.\n",
            "  [END SOURCES PROPERTY REQUIREMENTS]\n",
            "\n",
            "[END RESPONSE OUTPUT REQUIREMENTS]\n",
            "</message>\n",
            "<chat_history><message role=\"user\"><text>What are the different product categories we have?</text></message><message role=\"assistant\" /><message role=\"user\"><text>What is the top performing product by quantity of units sold?</text></message><message role=\"assistant\" /></chat_history>\n",
            "<message role=\"user\">Which country did we sell the most to in June 2008?</message> as xml, treating as text, error was: not well-formed (invalid token): line 41, column 78\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=58, prompt_tokens=1878, total_tokens=1936)\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_chat_completion_base:processing 2 tool calls in parallel.\n",
            "INFO:semantic_kernel.kernel:Calling SQL-GetEntitySchema function with args: {\"text\": \"sales by country in June 2008\"}\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-GetEntitySchema invoking.\n",
            "INFO:semantic_kernel.kernel:Calling SQL-GetEntitySchema function with args: {\"text\": \"sales data\"}\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-GetEntitySchema invoking.\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-03-15-preview \"HTTP/1.1 200 OK\"\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://open-ai-vector-db.search.windows.net/indexes('text-2-sql-index')/docs/search.post.search?api-version=REDACTED'\n",
            "Request method: 'POST'\n",
            "Request headers:\n",
            "    'Content-Type': 'application/json'\n",
            "    'Content-Length': '34658'\n",
            "    'api-key': 'REDACTED'\n",
            "    'Accept': 'application/json;odata.metadata=none'\n",
            "    'x-ms-client-request-id': '4b5adb26-706a-11ef-ae73-0242ac110002'\n",
            "    'User-Agent': 'azsdk-python-search-documents/11.6.0b4 Python/3.12.3 (Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36)'\n",
            "A body is sent with the request\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-03-15-preview \"HTTP/1.1 200 OK\"\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://open-ai-vector-db.search.windows.net/indexes('text-2-sql-index')/docs/search.post.search?api-version=REDACTED'\n",
            "Request method: 'POST'\n",
            "Request headers:\n",
            "    'Content-Type': 'application/json'\n",
            "    'Content-Length': '34688'\n",
            "    'api-key': 'REDACTED'\n",
            "    'Accept': 'application/json;odata.metadata=none'\n",
            "    'x-ms-client-request-id': '4b65b654-706a-11ef-ae73-0242ac110002'\n",
            "    'User-Agent': 'azsdk-python-search-documents/11.6.0b4 Python/3.12.3 (Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36)'\n",
            "A body is sent with the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 200\n",
            "Response headers:\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
            "    'Content-Encoding': 'REDACTED'\n",
            "    'Vary': 'REDACTED'\n",
            "    'Server': 'Microsoft-IIS/10.0'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Preference-Applied': 'REDACTED'\n",
            "    'OData-Version': 'REDACTED'\n",
            "    'request-id': '4b5adb26-706a-11ef-ae73-0242ac110002'\n",
            "    'elapsed-time': 'REDACTED'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Date': 'Wed, 11 Sep 2024 18:18:52 GMT'\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-GetEntitySchema succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.427427s\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 200\n",
            "Response headers:\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
            "    'Content-Encoding': 'REDACTED'\n",
            "    'Vary': 'REDACTED'\n",
            "    'Server': 'Microsoft-IIS/10.0'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Preference-Applied': 'REDACTED'\n",
            "    'OData-Version': 'REDACTED'\n",
            "    'request-id': '4b65b654-706a-11ef-ae73-0242ac110002'\n",
            "    'elapsed-time': 'REDACTED'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Date': 'Wed, 11 Sep 2024 18:18:52 GMT'\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-GetEntitySchema succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.501665s\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=74, prompt_tokens=5848, total_tokens=5922)\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_chat_completion_base:processing 1 tool calls in parallel.\n",
            "INFO:semantic_kernel.kernel:Calling SQL-RunSQLQuery function with args: {\"sql_query\":\"SELECT TOP 1 ShipToAddressID, SUM(TotalDue) as TotalSales FROM SalesLT.SalesOrderHeader WHERE OrderDate BETWEEN '2008-06-01' AND '2008-06-30' GROUP BY ShipToAddressID ORDER BY TotalSales DESC;\"}\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-RunSQLQuery invoking.\n",
            "INFO:root:Executing SQL Query\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-RunSQLQuery succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.269046s\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client:Retrying request to /chat/completions in 17.000000 seconds\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=40, prompt_tokens=5955, total_tokens=5995)\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_chat_completion_base:processing 1 tool calls in parallel.\n",
            "INFO:semantic_kernel.kernel:Calling SQL-RunSQLQuery function with args: {\"sql_query\":\"SELECT AddressLine1, City, StateProvince, CountryRegion FROM SalesLT.Address WHERE AddressID = 659;\"}\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-RunSQLQuery invoking.\n",
            "INFO:root:Executing SQL Query\n",
            "INFO:semantic_kernel.functions.kernel_function:Function SQL-RunSQLQuery succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.419786s\n",
            "INFO:httpx:HTTP Request: POST https://open-ai-gpt-001.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=266, prompt_tokens=6048, total_tokens=6314)\n",
            "INFO:semantic_kernel.functions.kernel_function:Function ChatBot-Chat succeeded.\n",
            "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 25.101880s\n",
            "INFO:root:Answer: { \n",
            "  \"answer\": \"The country where we sold the most in June 2008 is the United Kingdom, specifically to an address in Woolston, England [1][2].\", \n",
            "  \"sources\": [ \n",
            "    { \n",
            "      \"title\": \"Sales Order Header\", \n",
            "      \"chunk\": \"| ShipToAddressID | TotalSales     |\\n|-----------------|----------------|\\n| 659             | 119960.8240    |\\n\", \n",
            "      \"reference\": \"SELECT TOP 1 ShipToAddressID, SUM(TotalDue) as TotalSales FROM SalesLT.SalesOrderHeader WHERE OrderDate BETWEEN '2008-06-01' AND '2008-06-30' GROUP BY ShipToAddressID ORDER BY TotalSales DESC;\" \n",
            "    }, \n",
            "    { \n",
            "      \"title\": \"Address\", \n",
            "      \"chunk\": \"| AddressLine1              | City      | StateProvince | CountryRegion |\\n|---------------------------|-----------|---------------|---------------|\\n| Warrington Ldc Unit 25/2  | Woolston  | England       | United Kingdom|\\n\", \n",
            "      \"reference\": \"SELECT AddressLine1, City, StateProvince, CountryRegion FROM SalesLT.Address WHERE AddressID = 659;\" \n",
            "    } \n",
            "  ] \n",
            "}\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The country where we sold the most in June 2008 is the United Kingdom, specifically to an address in Woolston, England [1][2]."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "await ask_question(\"Which country did we sell the most to in June 2008?\", history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text2SQL with AutoGen & Azure OpenAI\n",
        "\n",
        "This notebook demonstrates how the AutoGen Agents can be integrated with Azure OpenAI to answer questions from the database based on the schemas provided. \n",
        "\n",
        "A multi-shot approach is used for SQL generation for more reliable results and reduced token usage. More details can be found in the README.md.\n",
        "\n",
        "### Dependencies\n",
        "\n",
        "To install dependencies for this demo:\n",
        "\n",
        "`uv sync --package autogen_text_2_sql`\n",
        "\n",
        "`uv add --editable ../text_2_sql_core/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is only needed for this notebook to work\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add the parent directory of `src` to the path\n",
        "sys.path.append(str(Path.cwd() / \"src\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dotenv\n",
        "import logging\n",
        "from autogen_agentchat.task import Console\n",
        "from autogen_text_2_sql.autogen_text_2_sql import AutoGenText2Sql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bot setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "agentic_text_2_sql = AutoGenText2Sql(target_engine=\"TSQL\", engine_specific_rules=\"Use TOP X to limit the number of rows returned instead of LIMIT X. NEVER USE LIMIT X as it produces a syntax error.\").agentic_flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = agentic_text_2_sql.run_stream(task=\"What are the total number of sales within 2008?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:autogen_core:Sending message of type GroupChatStart to group_chat_manager: {'message': TextMessage(source='user', models_usage=None, content='What are the total number of sales within 2008?')}\n",
            "INFO:autogen_core:Calling message handler for group_chat_manager/6d7e11b2-73d2-4b4d-9716-dd5596ded914 with message type GroupChatStart sent by Unknown\n",
            "INFO:autogen_core:Publishing message of type GroupChatStart to all subscribers: {'message': TextMessage(source='user', models_usage=None, content='What are the total number of sales within 2008?')}\n",
            "INFO:autogen_core:Publishing message of type GroupChatStart to all subscribers: {'message': TextMessage(source='user', models_usage=None, content='What are the total number of sales within 2008?')}\n",
            "INFO:root:Messages: [TextMessage(source='user', models_usage=None, content='What are the total number of sales within 2008?')]\n",
            "INFO:root:Decision: sql_query_cache_agent\n",
            "INFO:autogen_core:Publishing message of type GroupChatRequestPublish to all subscribers: {}\n",
            "INFO:autogen_core:Calling message handler for collect_output_messages with message type GroupChatStart published by group_chat_manager/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_agentchat.events:source='user' models_usage=None content='What are the total number of sales within 2008?'\n",
            "INFO:autogen_core:Calling message handler for sql_query_generation_agent with message type GroupChatStart published by group_chat_manager/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for sql_schema_selection_agent with message type GroupChatStart published by group_chat_manager/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for sql_query_correction_agent with message type GroupChatStart published by group_chat_manager/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for answer_agent with message type GroupChatStart published by group_chat_manager/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for question_decomposition_agent with message type GroupChatStart published by group_chat_manager/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for sql_query_cache_agent with message type GroupChatStart published by group_chat_manager/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for sql_query_cache_agent with message type GroupChatRequestPublish published by group_chat_manager/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:root:Fetching queries from cache based on the user question...\n",
            "INFO:autogen_core:Resolving response with message type NoneType for recipient None from group_chat_manager: None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- user ----------\n",
            "What are the total number of sales within 2008?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://aoai-text2sql-adi.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-03-15-preview \"HTTP/1.1 200 OK\"\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://aisearch-text2sql-adi.search.windows.net/indexes('text-2-sql-query-cache-index')/docs/search.post.search?api-version=REDACTED'\n",
            "Request method: 'POST'\n",
            "Request headers:\n",
            "    'Content-Type': 'application/json'\n",
            "    'Content-Length': '21275'\n",
            "    'api-key': 'REDACTED'\n",
            "    'Accept': 'application/json;odata.metadata=none'\n",
            "    'x-ms-client-request-id': '6faf61f0-b0f1-11ef-8373-0242ac110002'\n",
            "    'User-Agent': 'azsdk-python-search-documents/11.6.0b8 Python/3.12.7 (Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36)'\n",
            "A body is sent with the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 200\n",
            "Response headers:\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
            "    'Content-Encoding': 'REDACTED'\n",
            "    'Vary': 'REDACTED'\n",
            "    'Server': 'Microsoft-IIS/10.0'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Preference-Applied': 'REDACTED'\n",
            "    'OData-Version': 'REDACTED'\n",
            "    'request-id': '6faf61f0-b0f1-11ef-8373-0242ac110002'\n",
            "    'elapsed-time': 'REDACTED'\n",
            "    'Strict-Transport-Security': 'REDACTED'\n",
            "    'Date': 'Mon, 02 Dec 2024 21:07:28 GMT'\n",
            "INFO:root:Results: []\n",
            "INFO:autogen_core:Publishing message of type GroupChatMessage to all subscribers: {'message': TextMessage(source='sql_query_cache_agent', models_usage=None, content='{\"contains_pre_run_results\": false, \"cached_questions_and_schemas\": null}')}\n",
            "INFO:autogen_core:Publishing message of type GroupChatAgentResponse to all subscribers: {'agent_response': Response(chat_message=TextMessage(source='sql_query_cache_agent', models_usage=None, content='{\"contains_pre_run_results\": false, \"cached_questions_and_schemas\": null}'), inner_messages=None)}\n",
            "INFO:autogen_core:Calling message handler for collect_output_messages with message type GroupChatMessage published by sql_query_cache_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_agentchat.events:source='sql_query_cache_agent' models_usage=None content='{\"contains_pre_run_results\": false, \"cached_questions_and_schemas\": null}'\n",
            "INFO:autogen_core:Calling message handler for sql_query_generation_agent with message type GroupChatAgentResponse published by sql_query_cache_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for sql_schema_selection_agent with message type GroupChatAgentResponse published by sql_query_cache_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for sql_query_correction_agent with message type GroupChatAgentResponse published by sql_query_cache_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for answer_agent with message type GroupChatAgentResponse published by sql_query_cache_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for question_decomposition_agent with message type GroupChatAgentResponse published by sql_query_cache_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for group_chat_manager with message type GroupChatAgentResponse published by sql_query_cache_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:root:Messages: [TextMessage(source='user', models_usage=None, content='What are the total number of sales within 2008?'), TextMessage(source='sql_query_cache_agent', models_usage=None, content='{\"contains_pre_run_results\": false, \"cached_questions_and_schemas\": null}')]\n",
            "INFO:root:Decision: question_decomposition_agent\n",
            "INFO:autogen_core:Publishing message of type GroupChatRequestPublish to all subscribers: {}\n",
            "INFO:autogen_core:Calling message handler for question_decomposition_agent with message type GroupChatRequestPublish published by group_chat_manager/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- sql_query_cache_agent ----------\n",
            "{\"contains_pre_run_results\": false, \"cached_questions_and_schemas\": null}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://aoai-text2sql-adi.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-08-01-preview \"HTTP/1.1 200 OK\"\n",
            "INFO:autogen_core.events:{\"prompt_tokens\": 178, \"completion_tokens\": 20, \"type\": \"LLMCall\"}\n",
            "/workspaces/dstoolkit-text2sql-and-imageprocessing/.venv/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py:239: UserWarning: Resolved model mismatch: gpt-4o-mini-2024-07-18 != gpt-4o-mini. Model mapping may be incorrect.\n",
            "  result = await self._model_client.create(\n",
            "INFO:autogen_core:Publishing message of type GroupChatMessage to all subscribers: {'message': TextMessage(source='question_decomposition_agent', models_usage=RequestUsage(prompt_tokens=178, completion_tokens=20), content=\"[ { 'question': 'What is the total number of sales in 2008?', } ]\")}\n",
            "INFO:autogen_core:Publishing message of type GroupChatAgentResponse to all subscribers: {'agent_response': Response(chat_message=TextMessage(source='question_decomposition_agent', models_usage=RequestUsage(prompt_tokens=178, completion_tokens=20), content=\"[ { 'question': 'What is the total number of sales in 2008?', } ]\"), inner_messages=[])}\n",
            "INFO:autogen_core:Calling message handler for collect_output_messages with message type GroupChatMessage published by question_decomposition_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_agentchat.events:source='question_decomposition_agent' models_usage=RequestUsage(prompt_tokens=178, completion_tokens=20) content=\"[ { 'question': 'What is the total number of sales in 2008?', } ]\"\n",
            "INFO:autogen_core:Calling message handler for sql_query_generation_agent with message type GroupChatAgentResponse published by question_decomposition_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for sql_schema_selection_agent with message type GroupChatAgentResponse published by question_decomposition_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for sql_query_correction_agent with message type GroupChatAgentResponse published by question_decomposition_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for answer_agent with message type GroupChatAgentResponse published by question_decomposition_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for sql_query_cache_agent with message type GroupChatAgentResponse published by question_decomposition_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:autogen_core:Calling message handler for group_chat_manager with message type GroupChatAgentResponse published by question_decomposition_agent/6d7e11b2-73d2-4b4d-9716-dd5596ded914\n",
            "INFO:root:Messages: [TextMessage(source='user', models_usage=None, content='What are the total number of sales within 2008?'), TextMessage(source='sql_query_cache_agent', models_usage=None, content='{\"contains_pre_run_results\": false, \"cached_questions_and_schemas\": null}'), TextMessage(source='question_decomposition_agent', models_usage=RequestUsage(prompt_tokens=178, completion_tokens=20), content=\"[ { 'question': 'What is the total number of sales in 2008?', } ]\")]\n",
            "ERROR:autogen_core:Error processing publish message\n",
            "Traceback (most recent call last):\n",
            "  File \"/workspaces/dstoolkit-text2sql-and-imageprocessing/.venv/lib/python3.12/site-packages/autogen_core/application/_single_threaded_agent_runtime.py\", line 402, in _process_publish\n",
            "    await asyncio.gather(*responses)\n",
            "  File \"/workspaces/dstoolkit-text2sql-and-imageprocessing/.venv/lib/python3.12/site-packages/autogen_core/application/_single_threaded_agent_runtime.py\", line 394, in _on_message\n",
            "    return await agent.on_message(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/workspaces/dstoolkit-text2sql-and-imageprocessing/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py\", line 49, in on_message\n",
            "    return await super().on_message(message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/workspaces/dstoolkit-text2sql-and-imageprocessing/.venv/lib/python3.12/site-packages/autogen_core/components/_routed_agent.py\", line 484, in on_message\n",
            "    return await h(self, message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/workspaces/dstoolkit-text2sql-and-imageprocessing/.venv/lib/python3.12/site-packages/autogen_core/components/_routed_agent.py\", line 267, in wrapper\n",
            "    return_value = await func(self, message, ctx)  # type: ignore\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/workspaces/dstoolkit-text2sql-and-imageprocessing/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat_manager.py\", line 143, in handle_agent_response\n",
            "    speaker_topic_type = await self.select_speaker(self._message_thread)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/workspaces/dstoolkit-text2sql-and-imageprocessing/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_selector_group_chat.py\", line 76, in select_speaker\n",
            "    speaker = self._selector_func(thread)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/workspaces/dstoolkit-text2sql-and-imageprocessing/text_2_sql/autogen/src/autogen_text_2_sql/autogen_text_2_sql.py\", line 102, in selector\n",
            "    decomposition_result = json.loads(messages[-1].content)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/json/__init__.py\", line 346, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/json/decoder.py\", line 337, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/json/decoder.py\", line 353, in raw_decode\n",
            "    obj, end = self.scan_once(s, idx)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^\n",
            "json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 5 (char 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- question_decomposition_agent ----------\n",
            "[ { 'question': 'What is the total number of sales in 2008?', } ]\n",
            "[Prompt tokens: 178, Completion tokens: 20]\n",
            "---------- Summary ----------\n",
            "Number of messages: 3\n",
            "Finish reason: None\n",
            "Total prompt tokens: 178\n",
            "Total completion tokens: 20\n",
            "Duration: 2.31 seconds\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='What are the total number of sales within 2008?'), TextMessage(source='sql_query_cache_agent', models_usage=None, content='{\"contains_pre_run_results\": false, \"cached_questions_and_schemas\": null}'), TextMessage(source='question_decomposition_agent', models_usage=RequestUsage(prompt_tokens=178, completion_tokens=20), content=\"[ { 'question': 'What is the total number of sales in 2008?', } ]\")], stop_reason=None)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await Console(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate AutoGenText2SQL\n",
    "\n",
    "This notebook evaluates the AutoGenText2Sql class using the Spider test suite evaluation metric. \n",
    "\n",
    "The evaluation uses the official Spider evaluation approach, which requires:\n",
    "\n",
    "1. A gold file with format: `SQL query \\t database_id`\n",
    "2. A predictions file with generated SQL queries\n",
    "3. The Spider databases and schema information\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "To install dependencies for this evaluation:\n",
    "\n",
    "`uv sync --package autogen_text_2_sql`\n",
    "\n",
    "`uv add --editable text_2_sql_core`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import subprocess\n",
    "import dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the notebook directory path\n",
    "notebook_dir = Path().absolute()\n",
    "# Add the src directory to the path\n",
    "sys.path.append(str(notebook_dir / \"src\"))\n",
    "\n",
    "from autogen_text_2_sql import AutoGenText2Sql, QuestionPayload\n",
    "from autogen_text_2_sql.evaluation_utils import get_final_sql_query\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set up paths\n",
    "TEST_SUITE_DIR = Path(\"../test-suite-sql-eval\")\n",
    "SPIDER_DATA_DIR = Path(\"../spider_data\").absolute()\n",
    "DATABASE_DIR = SPIDER_DATA_DIR / \"database\"\n",
    "\n",
    "# Set SPIDER_DATA_DIR in environment so SQLiteSqlConnector can find tables.json\n",
    "os.environ[\"SPIDER_DATA_DIR\"] = str(SPIDER_DATA_DIR)\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the AutoGenText2Sql instance with SQLite-specific rules\n",
    "sqlite_rules = \"\"\"\n",
    "1. Use SQLite syntax\n",
    "2. Do not use Azure SQL specific functions\n",
    "3. Use strftime for date/time operations\n",
    "\"\"\"\n",
    "\n",
    "autogen_text2sql = AutoGenText2Sql(\n",
    "    engine_specific_rules=sqlite_rules,\n",
    "    use_case=\"Evaluating with Spider SQLite databases\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate SQL for a given question\n",
    "async def generate_sql(question):\n",
    "    # Capture log output\n",
    "    import io\n",
    "    log_capture = io.StringIO()\n",
    "    handler = logging.StreamHandler(log_capture)\n",
    "    logger.addHandler(handler)\n",
    "    \n",
    "    logger.info(f\"Processing question: {question}\")\n",
    "    logger.info(f\"Chat history: None\")\n",
    "    \n",
    "    # Track all SQL queries found\n",
    "    all_queries = []\n",
    "    final_query = None\n",
    "    \n",
    "    async for message in autogen_text2sql.process_question(QuestionPayload(question=question)):\n",
    "        if message.payload_type == \"answer_with_sources\":\n",
    "            # Extract from results\n",
    "            if hasattr(message.body, 'results'):\n",
    "                for q_results in message.body.results.values():\n",
    "                    for result in q_results:\n",
    "                        if isinstance(result, dict) and 'sql_query' in result:\n",
    "                            sql_query = result['sql_query'].strip()\n",
    "                            if sql_query and sql_query != \"SELECT NULL -- No query found\":\n",
    "                                all_queries.append(sql_query)\n",
    "                                logger.info(f\"Found SQL query in results: {sql_query}\")\n",
    "            \n",
    "            # Extract from sources\n",
    "            if hasattr(message.body, 'sources'):\n",
    "                for source in message.body.sources:\n",
    "                    if hasattr(source, 'sql_query'):\n",
    "                        sql_query = source.sql_query.strip()\n",
    "                        if sql_query and sql_query != \"SELECT NULL -- No query found\":\n",
    "                            all_queries.append(sql_query)\n",
    "                            logger.info(f\"Found SQL query in sources: {sql_query}\")\n",
    "    \n",
    "    # Get the log text\n",
    "    log_text = log_capture.getvalue()\n",
    "    \n",
    "    # Clean up logging\n",
    "    logger.removeHandler(handler)\n",
    "    log_capture.close()\n",
    "    \n",
    "    # Log all queries found\n",
    "    if all_queries:\n",
    "        logger.info(f\"All queries found: {all_queries}\")\n",
    "        # Select the most appropriate query - prefer DISTINCT queries for questions about unique values\n",
    "        question_lower = question.lower()\n",
    "        needs_distinct = any(word in question_lower for word in ['different', 'distinct', 'unique', 'all'])\n",
    "        \n",
    "        for query in reversed(all_queries):  # Look at queries in reverse order\n",
    "            if needs_distinct and 'DISTINCT' in query.upper():\n",
    "                final_query = query\n",
    "                break\n",
    "        if not final_query:  # If no DISTINCT query found when needed, use the last query\n",
    "            final_query = all_queries[-1]\n",
    "            # Add DISTINCT if needed but not present\n",
    "            if needs_distinct and 'DISTINCT' not in final_query.upper() and final_query.upper().startswith('SELECT '):\n",
    "                final_query = final_query.replace('SELECT ', 'SELECT DISTINCT ', 1)\n",
    "    \n",
    "    # Log final query\n",
    "    logger.info(f\"Final SQL query: {final_query or 'SELECT NULL -- No query found'}\")\n",
    "    \n",
    "    return final_query or \"SELECT NULL -- No query found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read Spider dev set and generate predictions\n",
    "async def generate_predictions(num_samples=None):\n",
    "    # Read Spider dev set\n",
    "    dev_file = SPIDER_DATA_DIR / \"dev.json\"\n",
    "    pred_file = TEST_SUITE_DIR / \"predictions.txt\"\n",
    "    gold_file = TEST_SUITE_DIR / \"gold.txt\"\n",
    "    \n",
    "    print(f\"Reading dev queries from {dev_file}\")\n",
    "    with open(dev_file) as f:\n",
    "        dev_data = json.load(f)\n",
    "    \n",
    "    # Limit number of samples if specified\n",
    "    if num_samples is not None:\n",
    "        dev_data = dev_data[:num_samples]\n",
    "        print(f\"\\nGenerating predictions for {num_samples} queries...\")\n",
    "    else:\n",
    "        print(f\"\\nGenerating predictions for all {len(dev_data)} queries...\")\n",
    "    \n",
    "    predictions = []\n",
    "    gold = []\n",
    "    \n",
    "    for idx, item in enumerate(dev_data, 1):\n",
    "        question = item['question']\n",
    "        db_id = item['db_id']\n",
    "        gold_query = item['query']\n",
    "        \n",
    "        print(f\"\\nProcessing query {idx}/{len(dev_data)} for database {db_id}\")\n",
    "        print(f\"Question: {question}\")\n",
    "        \n",
    "        # Update database connection string for current database\n",
    "        db_path = DATABASE_DIR / db_id / f\"{db_id}.sqlite\"\n",
    "        os.environ[\"Text2Sql__DatabaseConnectionString\"] = str(db_path)\n",
    "        os.environ[\"Text2Sql__DatabaseName\"] = db_id\n",
    "        \n",
    "        sql = await generate_sql(question)\n",
    "        predictions.append(f\"{sql}\\t{db_id}\")\n",
    "        gold.append(f\"{gold_query}\\t{db_id}\")\n",
    "        print(f\"Generated SQL: {sql}\")\n",
    "    \n",
    "    print(f\"\\nSaving predictions to {pred_file}\")\n",
    "    with open(pred_file, 'w') as f:\n",
    "        f.write('\\n'.join(predictions))\n",
    "        \n",
    "    print(f\"Saving gold queries to {gold_file}\")\n",
    "    with open(gold_file, 'w') as f:\n",
    "        f.write('\\n'.join(gold))\n",
    "    \n",
    "    return pred_file, gold_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation using the test suite evaluation script\n",
    "def run_evaluation():\n",
    "    # Use absolute paths to ensure correct file locations\n",
    "    gold_file = TEST_SUITE_DIR / \"gold.txt\"\n",
    "    pred_file = TEST_SUITE_DIR / \"predictions.txt\"\n",
    "    table_file = SPIDER_DATA_DIR / \"tables.json\"  # Use Spider's schema file\n",
    "    \n",
    "    print(f\"Starting evaluation at {time.strftime('%H:%M:%S')}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    cmd = [\n",
    "        \"python\",\n",
    "        str(TEST_SUITE_DIR / \"evaluation.py\"),\n",
    "        \"--gold\", str(gold_file),\n",
    "        \"--pred\", str(pred_file),\n",
    "        \"--db\", str(DATABASE_DIR),\n",
    "        \"--table\", str(table_file),\n",
    "        \"--etype\", \"all\",\n",
    "        \"--plug_value\",\n",
    "        \"--progress_bar_for_each_datapoint\"  # Show progress for each test input\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(\"==================\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "    print(f\"\\nEvaluation completed in {duration:.2f} seconds\")\n",
    "    print(f\"End time: {time.strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions first - now with optional num_samples parameter\n",
    "await generate_predictions(num_samples=20)  # Generate predictions for just 10 samples (takes about 4 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation at 20:53:48\n",
      "\n",
      "Evaluation Results:\n",
      "==================\n",
      "easy pred: SELECT COUNT(*) AS total_singers FROM singer;\n",
      "easy gold: SELECT count(*) FROM singer\n",
      "\n",
      "easy pred: SELECT COUNT(*) AS total_singers FROM singer;\n",
      "easy gold: SELECT count(*) FROM singer\n",
      "\n",
      "medium pred: SELECT * FROM singer ORDER BY Age DESC\n",
      "medium gold: SELECT name ,  country ,  age FROM singer ORDER BY age DESC\n",
      "\n",
      "medium pred: SELECT DISTINCT MAX(Age) AS Max_Age FROM singer WHERE Country = 'France'\n",
      "medium gold: SELECT avg(age) ,  min(age) ,  max(age) FROM singer WHERE country  =  'France'\n",
      "\n",
      "medium pred: SELECT DISTINCT MAX(Age) AS Maximum_Age FROM singer WHERE Country = 'French'\n",
      "medium gold: SELECT avg(age) ,  min(age) ,  max(age) FROM singer WHERE country  =  'France'\n",
      "\n",
      "medium pred: SELECT Song_Name, Song_release_year FROM singer WHERE Age = (SELECT MAX(Age) FROM singer)\n",
      "medium gold: SELECT song_name ,  song_release_year FROM singer ORDER BY age LIMIT 1\n",
      "\n",
      "medium pred: SELECT NULL -- No query found\n",
      "medium gold: SELECT song_name ,  song_release_year FROM singer ORDER BY age LIMIT 1\n",
      "\n",
      "medium pred: SELECT DISTINCT Country, COUNT(Singer_ID) AS NumberOfSingers FROM singer GROUP BY Country;\n",
      "medium gold: SELECT country ,  count(*) FROM singer GROUP BY country\n",
      "\n",
      "medium pred: SELECT Country, COUNT(*) AS SingerCount FROM singer GROUP BY Country;\n",
      "medium gold: SELECT country ,  count(*) FROM singer GROUP BY country\n",
      "\n",
      "hard pred: SELECT DISTINCT AVG(Age) AS average_age FROM singer;\n",
      "hard gold: SELECT song_name FROM singer WHERE age  >  (SELECT avg(age) FROM singer)\n",
      "\n",
      "hard pred: SELECT DISTINCT * FROM singer WHERE Age > (SELECT AVG(Age) FROM singer)\n",
      "hard gold: SELECT song_name FROM singer WHERE age  >  (SELECT avg(age) FROM singer)\n",
      "\n",
      "medium pred: SELECT NULL -- No query found\n",
      "medium gold: SELECT LOCATION ,  name FROM stadium WHERE capacity BETWEEN 5000 AND 10000\n",
      "\n",
      "medium pred: SELECT DISTINCT AVG(Capacity) AS Average_Capacity FROM stadium;\n",
      "medium gold: select max(capacity), average from stadium\n",
      "\n",
      "medium pred: SELECT DISTINCT MAX(Capacity) AS Max_Capacity FROM stadium;\n",
      "medium gold: select avg(capacity) ,  max(capacity) from stadium\n",
      "\n",
      "medium pred: SELECT Name, Average FROM stadium ORDER BY Average DESC LIMIT 1;\n",
      "medium gold: SELECT name ,  capacity FROM stadium ORDER BY average DESC LIMIT 1\n",
      "\n",
      "medium pred: SELECT Name, Average FROM stadium ORDER BY Average DESC LIMIT 1;\n",
      "medium gold: SELECT name ,  capacity FROM stadium ORDER BY average DESC LIMIT 1\n",
      "\n",
      "                     easy                 medium               hard                 extra                all                 \n",
      "count                4                    14                   2                    0                    20                  \n",
      "=====================   EXECUTION ACCURACY     =====================\n",
      "execution            1.000                0.286                0.000                0.000                0.400               \n",
      "\n",
      "====================== EXACT MATCHING ACCURACY =====================\n",
      "exact match          0.500                0.143                0.000                0.000                0.200               \n",
      "\n",
      "---------------------PARTIAL MATCHING ACCURACY----------------------\n",
      "select               1.000                0.500                0.000                0.000                0.556               \n",
      "select(no AGG)       1.000                0.500                0.000                0.000                0.556               \n",
      "where                1.000                0.500                1.000                0.000                0.800               \n",
      "where(no OP)         1.000                0.500                1.000                0.000                0.800               \n",
      "group(no Having)     0.000                0.000                0.000                0.000                0.000               \n",
      "group                0.000                0.000                0.000                0.000                0.000               \n",
      "order                0.000                1.000                0.000                0.000                1.000               \n",
      "and/or               1.000                1.000                1.000                0.000                1.000               \n",
      "IUEN                 0.000                0.000                0.000                0.000                0.000               \n",
      "keywords             1.000                0.833                1.000                0.000                0.889               \n",
      "---------------------- PARTIAL MATCHING RECALL ----------------------\n",
      "select               0.500                0.214                0.000                0.000                0.250               \n",
      "select(no AGG)       0.500                0.214                0.000                0.000                0.250               \n",
      "where                1.000                0.250                0.500                0.000                0.500               \n",
      "where(no OP)         1.000                0.250                0.500                0.000                0.500               \n",
      "group(no Having)     0.000                0.000                0.000                0.000                0.000               \n",
      "group                0.000                0.000                0.000                0.000                0.000               \n",
      "order                0.000                0.667                0.000                0.000                0.667               \n",
      "and/or               1.000                1.000                1.000                0.000                1.000               \n",
      "IUEN                 0.000                0.000                0.000                0.000                0.000               \n",
      "keywords             1.000                0.417                0.500                0.000                0.500               \n",
      "---------------------- PARTIAL MATCHING F1 --------------------------\n",
      "select               0.667                0.300                1.000                0.000                0.345               \n",
      "select(no AGG)       0.667                0.300                1.000                0.000                0.345               \n",
      "where                1.000                0.333                0.667                0.000                0.615               \n",
      "where(no OP)         1.000                0.333                0.667                0.000                0.615               \n",
      "group(no Having)     1.000                1.000                1.000                0.000                1.000               \n",
      "group                1.000                1.000                1.000                0.000                1.000               \n",
      "order                1.000                0.800                1.000                0.000                0.800               \n",
      "and/or               1.000                1.000                1.000                0.000                1.000               \n",
      "IUEN                 1.000                1.000                1.000                0.000                1.000               \n",
      "keywords             1.000                0.556                0.667                0.000                0.640               \n",
      "\n",
      "\n",
      "Evaluation completed in 4.21 seconds\n",
      "End time: 20:53:52\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "run_evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
